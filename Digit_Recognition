
import numpy as np
import pandas as pd 
import matplotlib.pyplot as plt
import itertools
from sklearn.metrics import confusion_matrix
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D
from keras.optimizers import RMSprop,Adam
from keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import ReduceLROnPlateau
import pickle


train = pd.read_csv("train.csv")
print(train.shape)

test = pd.read_csv("test.csv")
print(test.shape)

Y_train = train.iloc[:,0:1]
X_train=train.iloc[:,1:]

#Normalization
X_train = X_train / 255.0
test = test / 255.0

#Reshape keras 3 boyutlu kabul ediyor 28x28x1 gibi
X_train = X_train.values.reshape(-1,28,28,1)
test = test.values.reshape(-1,28,28,1)

from sklearn.preprocessing import OneHotEncoder
ohe = OneHotEncoder()
Y_train =ohe.fit_transform(Y_train).toarray()


from sklearn.model_selection import train_test_split
X_train , X_val ,Y_train , Y_val = train_test_split(X_train,Y_train,test_size=0.1,random_state=2)


#Modeli oluşturmaya başlıyoruz

model = Sequential()

#First Convolution
model.add(Conv2D(filters = 32, kernel_size =(5,5),
                 padding = 'Same',activation ='relu',
                 input_shape = (28,28,1)))
model.add(MaxPool2D(pool_size=(2,2),strides =(2,2)))
model.add(Dropout(0.20))

#Second Convolution without input shape
model.add(Conv2D(filters = 16, kernel_size =(3,3),
                 padding = 'Same',activation ='relu'))
model.add(MaxPool2D(pool_size=(2,2),strides =(2,2)))
model.add(Dropout(0.20))

#Neural Network part
model.add(Flatten())
model.add(Dense(256,activation = 'relu'))
model.add(Dropout(0.5))
model.add(Dense(10,activation = 'softmax'))

optimizer = Adam(lr=0.001 , beta_1 = 0.9 , beta_2 = 0.999)

#Compile the model
model.compile(optimizer=optimizer,
              loss = 'categorical_crossentropy',
              metrics = ['accuracy'])

epochs = 10
batch_size = 250 


datagen = ImageDataGenerator(
        featurewise_center = False , #set input mean to 0 over the dataset
        samplewise_center = False, #set each sample mean to zero
        featurewise_std_normalization = False, #divide inputs by std of the dataset
        samplewise_std_normalization = False, #divide each input by its std
        zca_whitening = False, #dimension reduction
        rotation_range = 0.05, #randoml rotate images 5 degrees
        zoom_range = 0.05, #randomly zoom 5 degree
        width_shift_range = 0.05, #randomly horizontal shift 5 degrees
        height_shift_range = 0.05, #randomly vertical shift 5 degrees
        horizontal_flip = False, # randomly flip images
        vertical_flip = False) #randomly flip images

datagen.fit(X_train)



#Model fitleniyor
history = model.fit_generator(datagen.flow(X_train,Y_train,batch_size = batch_size),
                                 validation_data = (X_val,Y_val),
                                 steps_per_epoch = X_train.shape[0] // batch_size,
                                 epochs = epochs)


#Model kaydediliyor
dosya = 'model_digit_recognition'
pickle.dump(model,open(dosya,'wb'))



#Model Yukleniyor
model_pickle = pickle.load(open('model_digit_recognition','rb'))


#Tahmin yapılıyor
y_pred = model_pickle.predict(X_val)

#one hot encoderı tekli arraye dönüştürüyor
y_pred_classes = np.argmax(y_pred,axis=1) 
Y_true =np.argmax(Y_val,axis=1)

cm = confusion_matrix(Y_true,y_pred_classes)
print(cm)


#Tahmini Son hale getirme
index = []
for i in range(0,4200):
    index.append(i)
sonuc =pd.DataFrame(data = index , index = range(4200), columns = ['ImageId'])   
sonuc['Label'] = y_pred_classes


#Test Değerleri Prediction
test_results = model_pickle.predict(test)
test_results = np.argmax(test_results,axis=1)



#Tahmini Son hale getirme
index_2 = []
for i in range(1,28001):
    index_2.append(i)
Test_sonuc =pd.DataFrame(data = index_2 , index = range(28000) , columns = ['ImageId'])   
Test_sonuc['Label'] = test_results

Test_sonuc.to_csv('test_sonuc.csv',index=False, na_rep='-')
